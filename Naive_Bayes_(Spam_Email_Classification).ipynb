{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HmwXo48VIGG",
        "outputId": "30471517-742d-4d43-ce9c-4582cf98621f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords # There are some words in a sentence; those do not carry enough information and therefore even if we remove those, it does not affect much the and it also saves commputational power.\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_csv('emails.csv')\n",
        "text_column = 'text'\n",
        "spam_column = 'spam'"
      ],
      "metadata": {
        "id": "1P-m7LaOVaix"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Remove punctuation and stopwords**"
      ],
      "metadata": {
        "id": "n6pg5nOdV1_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HGBIDSFDVw5K",
        "outputId": "23835f93-ad14-457b-e0b3-333f2917d245"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  spam\n",
              "0  Subject: naturally irresistible your corporate...     1\n",
              "1  Subject: the stock trading gunslinger  fanny i...     1\n",
              "2  Subject: unbelievable new homes made easy  im ...     1\n",
              "3  Subject: 4 color printing special  request add...     1\n",
              "4  Subject: do not have money , get software cds ...     1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-99f04994-f22b-429a-bc4e-26b8363e90d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99f04994-f22b-429a-bc4e-26b8363e90d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-3890c57b-7cbc-4e93-9569-dda51ae4c6f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3890c57b-7cbc-4e93-9569-dda51ae4c6f8')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-3890c57b-7cbc-4e93-9569-dda51ae4c6f8 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99f04994-f22b-429a-bc4e-26b8363e90d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99f04994-f22b-429a-bc4e-26b8363e90d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "DML-VSnyV4bM",
        "outputId": "fabe8bf4-8b2b-4a62-913d-1b19eff94be2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Subject: naturally irresistible your corporate identity  lt is really hard to recollect a company : the  market is full of suqgestions and the information isoverwhelminq ; but a good  catchy logo , stylish statlonery and outstanding website  will make the task much easier .  we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader : it isguite ciear that  without good products , effective business organization and practicable aim it  will be hotat nowadays market ; but we do promise that your marketing efforts  will become much more effective . here is the list of clear  benefits : creativeness : hand - made , original logos , specially done  to reflect your distinctive company image . convenience : logo and stationery  are provided in all formats ; easy - to - use content management system letsyou  change your website content and even its structure . promptness : you  will see logo drafts within three business days . affordability : your  marketing break - through shouldn ' t make gaps in your budget . 100 % satisfaction  guaranteed : we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration . have a look at our  portfolio _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ not interested . . . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopword = set(stopwords.words('english'))\n",
        "stopword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PnvS9V_V5w7",
        "outputId": "3940a4cc-a7e8-4a6a-8bc1-81b208c84df2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('bengali')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNtM5j9UV7Oi",
        "outputId": "c802dd3a-cdcc-46b8-c34b-eaa0031813a4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['অতএব',\n",
              " 'অথচ',\n",
              " 'অথবা',\n",
              " 'অনুযায়ী',\n",
              " 'অনেক',\n",
              " 'অনেকে',\n",
              " 'অনেকেই',\n",
              " 'অন্তত',\n",
              " 'অন্য',\n",
              " 'অবধি',\n",
              " 'অবশ্য',\n",
              " 'অর্থাত',\n",
              " 'আই',\n",
              " 'আগামী',\n",
              " 'আগে',\n",
              " 'আগেই',\n",
              " 'আছে',\n",
              " 'আজ',\n",
              " 'আদ্যভাগে',\n",
              " 'আপনার',\n",
              " 'আপনি',\n",
              " 'আবার',\n",
              " 'আমরা',\n",
              " 'আমাকে',\n",
              " 'আমাদের',\n",
              " 'আমার',\n",
              " 'আমি',\n",
              " 'আর',\n",
              " 'আরও',\n",
              " 'ই',\n",
              " 'ইত্যাদি',\n",
              " 'ইহা',\n",
              " 'উচিত',\n",
              " 'উত্তর',\n",
              " 'উনি',\n",
              " 'উপর',\n",
              " 'উপরে',\n",
              " 'এ',\n",
              " 'এঁদের',\n",
              " 'এঁরা',\n",
              " 'এই',\n",
              " 'একই',\n",
              " 'একটি',\n",
              " 'একবার',\n",
              " 'একে',\n",
              " 'এক্',\n",
              " 'এখন',\n",
              " 'এখনও',\n",
              " 'এখানে',\n",
              " 'এখানেই',\n",
              " 'এটা',\n",
              " 'এটাই',\n",
              " 'এটি',\n",
              " 'এত',\n",
              " 'এতটাই',\n",
              " 'এতে',\n",
              " 'এদের',\n",
              " 'এব',\n",
              " 'এবং',\n",
              " 'এবার',\n",
              " 'এমন',\n",
              " 'এমনকী',\n",
              " 'এমনি',\n",
              " 'এর',\n",
              " 'এরা',\n",
              " 'এল',\n",
              " 'এস',\n",
              " 'এসে',\n",
              " 'ঐ',\n",
              " 'ও',\n",
              " 'ওঁদের',\n",
              " 'ওঁর',\n",
              " 'ওঁরা',\n",
              " 'ওই',\n",
              " 'ওকে',\n",
              " 'ওখানে',\n",
              " 'ওদের',\n",
              " 'ওর',\n",
              " 'ওরা',\n",
              " 'কখনও',\n",
              " 'কত',\n",
              " 'কবে',\n",
              " 'কমনে',\n",
              " 'কয়েক',\n",
              " 'কয়েকটি',\n",
              " 'করছে',\n",
              " 'করছেন',\n",
              " 'করতে',\n",
              " 'করবে',\n",
              " 'করবেন',\n",
              " 'করলে',\n",
              " 'করলেন',\n",
              " 'করা',\n",
              " 'করাই',\n",
              " 'করায়',\n",
              " 'করার',\n",
              " 'করি',\n",
              " 'করিতে',\n",
              " 'করিয়া',\n",
              " 'করিয়ে',\n",
              " 'করে',\n",
              " 'করেই',\n",
              " 'করেছিলেন',\n",
              " 'করেছে',\n",
              " 'করেছেন',\n",
              " 'করেন',\n",
              " 'কাউকে',\n",
              " 'কাছ',\n",
              " 'কাছে',\n",
              " 'কাজ',\n",
              " 'কাজে',\n",
              " 'কারও',\n",
              " 'কারণ',\n",
              " 'কি',\n",
              " 'কিংবা',\n",
              " 'কিছু',\n",
              " 'কিছুই',\n",
              " 'কিন্তু',\n",
              " 'কী',\n",
              " 'কে',\n",
              " 'কেউ',\n",
              " 'কেউই',\n",
              " 'কেখা',\n",
              " 'কেন',\n",
              " 'কোটি',\n",
              " 'কোন',\n",
              " 'কোনও',\n",
              " 'কোনো',\n",
              " 'ক্ষেত্রে',\n",
              " 'কয়েক',\n",
              " 'খুব',\n",
              " 'গিয়ে',\n",
              " 'গিয়েছে',\n",
              " 'গিয়ে',\n",
              " 'গুলি',\n",
              " 'গেছে',\n",
              " 'গেল',\n",
              " 'গেলে',\n",
              " 'গোটা',\n",
              " 'চলে',\n",
              " 'চান',\n",
              " 'চায়',\n",
              " 'চার',\n",
              " 'চালু',\n",
              " 'চেয়ে',\n",
              " 'চেষ্টা',\n",
              " 'ছাড়া',\n",
              " 'ছাড়াও',\n",
              " 'ছিল',\n",
              " 'ছিলেন',\n",
              " 'জন',\n",
              " 'জনকে',\n",
              " 'জনের',\n",
              " 'জন্য',\n",
              " 'জন্যওজে',\n",
              " 'জানতে',\n",
              " 'জানা',\n",
              " 'জানানো',\n",
              " 'জানায়',\n",
              " 'জানিয়ে',\n",
              " 'জানিয়েছে',\n",
              " 'জে',\n",
              " 'জ্নজন',\n",
              " 'টি',\n",
              " 'ঠিক',\n",
              " 'তখন',\n",
              " 'তত',\n",
              " 'তথা',\n",
              " 'তবু',\n",
              " 'তবে',\n",
              " 'তা',\n",
              " 'তাঁকে',\n",
              " 'তাঁদের',\n",
              " 'তাঁর',\n",
              " 'তাঁরা',\n",
              " 'তাঁাহারা',\n",
              " 'তাই',\n",
              " 'তাও',\n",
              " 'তাকে',\n",
              " 'তাতে',\n",
              " 'তাদের',\n",
              " 'তার',\n",
              " 'তারপর',\n",
              " 'তারা',\n",
              " 'তারৈ',\n",
              " 'তাহলে',\n",
              " 'তাহা',\n",
              " 'তাহাতে',\n",
              " 'তাহার',\n",
              " 'তিনঐ',\n",
              " 'তিনি',\n",
              " 'তিনিও',\n",
              " 'তুমি',\n",
              " 'তুলে',\n",
              " 'তেমন',\n",
              " 'তো',\n",
              " 'তোমার',\n",
              " 'থাকবে',\n",
              " 'থাকবেন',\n",
              " 'থাকা',\n",
              " 'থাকায়',\n",
              " 'থাকে',\n",
              " 'থাকেন',\n",
              " 'থেকে',\n",
              " 'থেকেই',\n",
              " 'থেকেও',\n",
              " 'দিকে',\n",
              " 'দিতে',\n",
              " 'দিন',\n",
              " 'দিয়ে',\n",
              " 'দিয়েছে',\n",
              " 'দিয়েছেন',\n",
              " 'দিলেন',\n",
              " 'দু',\n",
              " 'দুই',\n",
              " 'দুটি',\n",
              " 'দুটো',\n",
              " 'দেওয়া',\n",
              " 'দেওয়ার',\n",
              " 'দেওয়া',\n",
              " 'দেখতে',\n",
              " 'দেখা',\n",
              " 'দেখে',\n",
              " 'দেন',\n",
              " 'দেয়',\n",
              " 'দ্বারা',\n",
              " 'ধরা',\n",
              " 'ধরে',\n",
              " 'ধামার',\n",
              " 'নতুন',\n",
              " 'নয়',\n",
              " 'না',\n",
              " 'নাই',\n",
              " 'নাকি',\n",
              " 'নাগাদ',\n",
              " 'নানা',\n",
              " 'নিজে',\n",
              " 'নিজেই',\n",
              " 'নিজেদের',\n",
              " 'নিজের',\n",
              " 'নিতে',\n",
              " 'নিয়ে',\n",
              " 'নিয়ে',\n",
              " 'নেই',\n",
              " 'নেওয়া',\n",
              " 'নেওয়ার',\n",
              " 'নেওয়া',\n",
              " 'নয়',\n",
              " 'পক্ষে',\n",
              " 'পর',\n",
              " 'পরে',\n",
              " 'পরেই',\n",
              " 'পরেও',\n",
              " 'পর্যন্ত',\n",
              " 'পাওয়া',\n",
              " 'পাচ',\n",
              " 'পারি',\n",
              " 'পারে',\n",
              " 'পারেন',\n",
              " 'পি',\n",
              " 'পেয়ে',\n",
              " 'পেয়্র্',\n",
              " 'প্রতি',\n",
              " 'প্রথম',\n",
              " 'প্রভৃতি',\n",
              " 'প্রযন্ত',\n",
              " 'প্রাথমিক',\n",
              " 'প্রায়',\n",
              " 'প্রায়',\n",
              " 'ফলে',\n",
              " 'ফিরে',\n",
              " 'ফের',\n",
              " 'বক্তব্য',\n",
              " 'বদলে',\n",
              " 'বন',\n",
              " 'বরং',\n",
              " 'বলতে',\n",
              " 'বলল',\n",
              " 'বললেন',\n",
              " 'বলা',\n",
              " 'বলে',\n",
              " 'বলেছেন',\n",
              " 'বলেন',\n",
              " 'বসে',\n",
              " 'বহু',\n",
              " 'বা',\n",
              " 'বাদে',\n",
              " 'বার',\n",
              " 'বি',\n",
              " 'বিনা',\n",
              " 'বিভিন্ন',\n",
              " 'বিশেষ',\n",
              " 'বিষয়টি',\n",
              " 'বেশ',\n",
              " 'বেশি',\n",
              " 'ব্যবহার',\n",
              " 'ব্যাপারে',\n",
              " 'ভাবে',\n",
              " 'ভাবেই',\n",
              " 'মতো',\n",
              " 'মতোই',\n",
              " 'মধ্যভাগে',\n",
              " 'মধ্যে',\n",
              " 'মধ্যেই',\n",
              " 'মধ্যেও',\n",
              " 'মনে',\n",
              " 'মাত্র',\n",
              " 'মাধ্যমে',\n",
              " 'মোট',\n",
              " 'মোটেই',\n",
              " 'যখন',\n",
              " 'যত',\n",
              " 'যতটা',\n",
              " 'যথেষ্ট',\n",
              " 'যদি',\n",
              " 'যদিও',\n",
              " 'যা',\n",
              " 'যাঁর',\n",
              " 'যাঁরা',\n",
              " 'যাওয়া',\n",
              " 'যাওয়ার',\n",
              " 'যাওয়া',\n",
              " 'যাকে',\n",
              " 'যাচ্ছে',\n",
              " 'যাতে',\n",
              " 'যাদের',\n",
              " 'যান',\n",
              " 'যাবে',\n",
              " 'যায়',\n",
              " 'যার',\n",
              " 'যারা',\n",
              " 'যিনি',\n",
              " 'যে',\n",
              " 'যেখানে',\n",
              " 'যেতে',\n",
              " 'যেন',\n",
              " 'যেমন',\n",
              " 'র',\n",
              " 'রকম',\n",
              " 'রয়েছে',\n",
              " 'রাখা',\n",
              " 'রেখে',\n",
              " 'লক্ষ',\n",
              " 'শুধু',\n",
              " 'শুরু',\n",
              " 'সঙ্গে',\n",
              " 'সঙ্গেও',\n",
              " 'সব',\n",
              " 'সবার',\n",
              " 'সমস্ত',\n",
              " 'সম্প্রতি',\n",
              " 'সহ',\n",
              " 'সহিত',\n",
              " 'সাধারণ',\n",
              " 'সামনে',\n",
              " 'সি',\n",
              " 'সুতরাং',\n",
              " 'সে',\n",
              " 'সেই',\n",
              " 'সেখান',\n",
              " 'সেখানে',\n",
              " 'সেটা',\n",
              " 'সেটাই',\n",
              " 'সেটাও',\n",
              " 'সেটি',\n",
              " 'স্পষ্ট',\n",
              " 'স্বয়ং',\n",
              " 'হইতে',\n",
              " 'হইবে',\n",
              " 'হইয়া',\n",
              " 'হওয়া',\n",
              " 'হওয়ায়',\n",
              " 'হওয়ার',\n",
              " 'হচ্ছে',\n",
              " 'হত',\n",
              " 'হতে',\n",
              " 'হতেই',\n",
              " 'হন',\n",
              " 'হবে',\n",
              " 'হবেন',\n",
              " 'হয়',\n",
              " 'হয়তো',\n",
              " 'হয়নি',\n",
              " 'হয়ে',\n",
              " 'হয়েই',\n",
              " 'হয়েছিল',\n",
              " 'হয়েছে',\n",
              " 'হয়েছেন',\n",
              " 'হল',\n",
              " 'হলে',\n",
              " 'হলেই',\n",
              " 'হলেও',\n",
              " 'হলো',\n",
              " 'হাজার',\n",
              " 'হিসাবে',\n",
              " 'হৈলে',\n",
              " 'হোক',\n",
              " 'হয়']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('italian')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_pOzMFkV9zL",
        "outputId": "2d9b8c54-0863-4089-bfcb-9c6490320e36"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ad',\n",
              " 'al',\n",
              " 'allo',\n",
              " 'ai',\n",
              " 'agli',\n",
              " 'all',\n",
              " 'agl',\n",
              " 'alla',\n",
              " 'alle',\n",
              " 'con',\n",
              " 'col',\n",
              " 'coi',\n",
              " 'da',\n",
              " 'dal',\n",
              " 'dallo',\n",
              " 'dai',\n",
              " 'dagli',\n",
              " 'dall',\n",
              " 'dagl',\n",
              " 'dalla',\n",
              " 'dalle',\n",
              " 'di',\n",
              " 'del',\n",
              " 'dello',\n",
              " 'dei',\n",
              " 'degli',\n",
              " 'dell',\n",
              " 'degl',\n",
              " 'della',\n",
              " 'delle',\n",
              " 'in',\n",
              " 'nel',\n",
              " 'nello',\n",
              " 'nei',\n",
              " 'negli',\n",
              " 'nell',\n",
              " 'negl',\n",
              " 'nella',\n",
              " 'nelle',\n",
              " 'su',\n",
              " 'sul',\n",
              " 'sullo',\n",
              " 'sui',\n",
              " 'sugli',\n",
              " 'sull',\n",
              " 'sugl',\n",
              " 'sulla',\n",
              " 'sulle',\n",
              " 'per',\n",
              " 'tra',\n",
              " 'contro',\n",
              " 'io',\n",
              " 'tu',\n",
              " 'lui',\n",
              " 'lei',\n",
              " 'noi',\n",
              " 'voi',\n",
              " 'loro',\n",
              " 'mio',\n",
              " 'mia',\n",
              " 'miei',\n",
              " 'mie',\n",
              " 'tuo',\n",
              " 'tua',\n",
              " 'tuoi',\n",
              " 'tue',\n",
              " 'suo',\n",
              " 'sua',\n",
              " 'suoi',\n",
              " 'sue',\n",
              " 'nostro',\n",
              " 'nostra',\n",
              " 'nostri',\n",
              " 'nostre',\n",
              " 'vostro',\n",
              " 'vostra',\n",
              " 'vostri',\n",
              " 'vostre',\n",
              " 'mi',\n",
              " 'ti',\n",
              " 'ci',\n",
              " 'vi',\n",
              " 'lo',\n",
              " 'la',\n",
              " 'li',\n",
              " 'le',\n",
              " 'gli',\n",
              " 'ne',\n",
              " 'il',\n",
              " 'un',\n",
              " 'uno',\n",
              " 'una',\n",
              " 'ma',\n",
              " 'ed',\n",
              " 'se',\n",
              " 'perché',\n",
              " 'anche',\n",
              " 'come',\n",
              " 'dov',\n",
              " 'dove',\n",
              " 'che',\n",
              " 'chi',\n",
              " 'cui',\n",
              " 'non',\n",
              " 'più',\n",
              " 'quale',\n",
              " 'quanto',\n",
              " 'quanti',\n",
              " 'quanta',\n",
              " 'quante',\n",
              " 'quello',\n",
              " 'quelli',\n",
              " 'quella',\n",
              " 'quelle',\n",
              " 'questo',\n",
              " 'questi',\n",
              " 'questa',\n",
              " 'queste',\n",
              " 'si',\n",
              " 'tutto',\n",
              " 'tutti',\n",
              " 'a',\n",
              " 'c',\n",
              " 'e',\n",
              " 'i',\n",
              " 'l',\n",
              " 'o',\n",
              " 'ho',\n",
              " 'hai',\n",
              " 'ha',\n",
              " 'abbiamo',\n",
              " 'avete',\n",
              " 'hanno',\n",
              " 'abbia',\n",
              " 'abbiate',\n",
              " 'abbiano',\n",
              " 'avrò',\n",
              " 'avrai',\n",
              " 'avrà',\n",
              " 'avremo',\n",
              " 'avrete',\n",
              " 'avranno',\n",
              " 'avrei',\n",
              " 'avresti',\n",
              " 'avrebbe',\n",
              " 'avremmo',\n",
              " 'avreste',\n",
              " 'avrebbero',\n",
              " 'avevo',\n",
              " 'avevi',\n",
              " 'aveva',\n",
              " 'avevamo',\n",
              " 'avevate',\n",
              " 'avevano',\n",
              " 'ebbi',\n",
              " 'avesti',\n",
              " 'ebbe',\n",
              " 'avemmo',\n",
              " 'aveste',\n",
              " 'ebbero',\n",
              " 'avessi',\n",
              " 'avesse',\n",
              " 'avessimo',\n",
              " 'avessero',\n",
              " 'avendo',\n",
              " 'avuto',\n",
              " 'avuta',\n",
              " 'avuti',\n",
              " 'avute',\n",
              " 'sono',\n",
              " 'sei',\n",
              " 'è',\n",
              " 'siamo',\n",
              " 'siete',\n",
              " 'sia',\n",
              " 'siate',\n",
              " 'siano',\n",
              " 'sarò',\n",
              " 'sarai',\n",
              " 'sarà',\n",
              " 'saremo',\n",
              " 'sarete',\n",
              " 'saranno',\n",
              " 'sarei',\n",
              " 'saresti',\n",
              " 'sarebbe',\n",
              " 'saremmo',\n",
              " 'sareste',\n",
              " 'sarebbero',\n",
              " 'ero',\n",
              " 'eri',\n",
              " 'era',\n",
              " 'eravamo',\n",
              " 'eravate',\n",
              " 'erano',\n",
              " 'fui',\n",
              " 'fosti',\n",
              " 'fu',\n",
              " 'fummo',\n",
              " 'foste',\n",
              " 'furono',\n",
              " 'fossi',\n",
              " 'fosse',\n",
              " 'fossimo',\n",
              " 'fossero',\n",
              " 'essendo',\n",
              " 'faccio',\n",
              " 'fai',\n",
              " 'facciamo',\n",
              " 'fanno',\n",
              " 'faccia',\n",
              " 'facciate',\n",
              " 'facciano',\n",
              " 'farò',\n",
              " 'farai',\n",
              " 'farà',\n",
              " 'faremo',\n",
              " 'farete',\n",
              " 'faranno',\n",
              " 'farei',\n",
              " 'faresti',\n",
              " 'farebbe',\n",
              " 'faremmo',\n",
              " 'fareste',\n",
              " 'farebbero',\n",
              " 'facevo',\n",
              " 'facevi',\n",
              " 'faceva',\n",
              " 'facevamo',\n",
              " 'facevate',\n",
              " 'facevano',\n",
              " 'feci',\n",
              " 'facesti',\n",
              " 'fece',\n",
              " 'facemmo',\n",
              " 'faceste',\n",
              " 'fecero',\n",
              " 'facessi',\n",
              " 'facesse',\n",
              " 'facessimo',\n",
              " 'facessero',\n",
              " 'facendo',\n",
              " 'sto',\n",
              " 'stai',\n",
              " 'sta',\n",
              " 'stiamo',\n",
              " 'stanno',\n",
              " 'stia',\n",
              " 'stiate',\n",
              " 'stiano',\n",
              " 'starò',\n",
              " 'starai',\n",
              " 'starà',\n",
              " 'staremo',\n",
              " 'starete',\n",
              " 'staranno',\n",
              " 'starei',\n",
              " 'staresti',\n",
              " 'starebbe',\n",
              " 'staremmo',\n",
              " 'stareste',\n",
              " 'starebbero',\n",
              " 'stavo',\n",
              " 'stavi',\n",
              " 'stava',\n",
              " 'stavamo',\n",
              " 'stavate',\n",
              " 'stavano',\n",
              " 'stetti',\n",
              " 'stesti',\n",
              " 'stette',\n",
              " 'stemmo',\n",
              " 'steste',\n",
              " 'stettero',\n",
              " 'stessi',\n",
              " 'stesse',\n",
              " 'stessimo',\n",
              " 'stessero',\n",
              " 'stando']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e59Ze2pyWAij",
        "outputId": "b9715525-1080-46ae-db22-1ea6103f62cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.text[200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "gg2TQVIoWCaC",
        "outputId": "f17d6152-06c4-4d5d-d3d9-2e059a9ef10c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Subject: for your information  dear homeowner ,  after completing the review we are pleased to offer you the following ,  your current mortgage qualifies you for more than a 3 % lower rate !  ! ! u . s mortgage rates have never been lower ! ! !  millions of americans have re - financed this month alone !  so why not you ?  go here to make that change .  if you prefer to be left out of this amazing offer go here .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "x8HqJcNZWD1a",
        "outputId": "d2e3d6c8-2aa1-4e0b-e1db-40a3805f30d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'DaTa'.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Aekerp-EWFEN",
        "outputId": "f2d14f4b-0323-44a8-b62d-d092f8ab7197"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Remove punctuation (using List Comprehension)\n",
        "    remove_punc = [char for char in text if char not in string.punctuation]\n",
        "    clean_words = ''.join(remove_punc) # char joining\n",
        "\n",
        "    # Remove stopwords\n",
        "    text = ([word for word in clean_words.split() if word.lower() not in stopword]) #converting all the data into lower format\n",
        "    return text #text column contains all the text\n"
      ],
      "metadata": {
        "id": "teGXLuYtWGUS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[text_column] = data[text_column].apply(preprocess_text)\n",
        "\n",
        "# after preprocessing data (removing punctuation, removing stopwords, converting into lower format), the preprocessed text will be in data[text_column]. These are individual token.\n",
        "# Ex: Subject, naturally, irresistible, corporate -> Subject is a token, naturally is another token, etc."
      ],
      "metadata": {
        "id": "-uS9sze-WHxh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[text_column]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrdxGZFJWI_U",
        "outputId": "a2d58e9a-ff27-4e8f-c063-106401e5b42c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [Subject, naturally, irresistible, corporate, ...\n",
              "1       [Subject, stock, trading, gunslinger, fanny, m...\n",
              "2       [Subject, unbelievable, new, homes, made, easy...\n",
              "3       [Subject, 4, color, printing, special, request...\n",
              "4       [Subject, money, get, software, cds, software,...\n",
              "                              ...                        \n",
              "6373    [Subject, research, development, charges, gpg,...\n",
              "6374    [Subject, receipts, visit, jim, thanks, invita...\n",
              "6375    [Subject, enron, case, study, update, wow, day...\n",
              "6376    [Subject, interest, david, please, call, shirl...\n",
              "6377    [Subject, news, aurora, 5, 2, update, aurora, ...\n",
              "Name: text, Length: 6378, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Lemmatization** (Normalizing the text)"
      ],
      "metadata": {
        "id": "5FFkRMHFWLyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in text]) #It will lemmatize each word from the text data and the normalized text will be in the lemmatized_text.\n",
        "    return lemmatized_text\n",
        "\n",
        "data[text_column] = data[text_column].apply(lemmatize_text)\n"
      ],
      "metadata": {
        "id": "b_4NKkytWKR6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[text_column] #The lemmatized_text will be in data[text_column]."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECw0Mk4HWPtS",
        "outputId": "57ff84a5-f925-4199-da88-2c8a77dbe377"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Subject naturally irresistible corporate ident...\n",
              "1       Subject stock trading gunslinger fanny merrill...\n",
              "2       Subject unbelievable new home made easy im wan...\n",
              "3       Subject 4 color printing special request addit...\n",
              "4       Subject money get software cd software compati...\n",
              "                              ...                        \n",
              "6373    Subject research development charge gpg forwar...\n",
              "6374    Subject receipt visit jim thanks invitation vi...\n",
              "6375    Subject enron case study update wow day super ...\n",
              "6376    Subject interest david please call shirley cre...\n",
              "6377    Subject news aurora 5 2 update aurora version ...\n",
              "Name: text, Length: 6378, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: TF-IDF vectorizer**"
      ],
      "metadata": {
        "id": "ZRtrtEruWTXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer() #TfidfVectorizer() -> object create.\n",
        "\n",
        "x = vectorizer.fit_transform(data[text_column])\n",
        "y = data[spam_column]\n"
      ],
      "metadata": {
        "id": "aNGo8mm_WRvn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kbB6-vfWVPm",
        "outputId": "958a916b-5379-4ab3-bdbb-846f5b0dc8a7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.11973089, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Fit models**"
      ],
      "metadata": {
        "id": "veqQoaHfWYr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DMw_plQmWXPz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Performance evaluation** (BernoulliNB performs better for the text data)"
      ],
      "metadata": {
        "id": "TyijB0KZWa_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    MultinomialNB(),\n",
        "    BernoulliNB()\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    model.fit(xtrain, ytrain)\n",
        "\n",
        "    ypred = model.predict(xtest)\n",
        "    ypred_proba = model.predict_proba(xtest)[:, 1] # Since I am interested in the probabilities of the positive class, I am using the indexing [:, 1] to select the second column (index 1) from the predicted probabilities.\n",
        "\n",
        "    print(f\"Model: {type(model).__name__}\")\n",
        "    print('Accuracy Score =',model.score(xtest, ytest))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(ytest, ypred))\n",
        "    print(\"AUC Score:\", roc_auc_score(ytest, ypred_proba))\n",
        "\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toeu4bBMWc5e",
        "outputId": "8d4b2766-c76d-4214-d955-2826749ff03f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: MultinomialNB\n",
            "Accuracy Score = 0.8793103448275862\n",
            "Confusion Matrix:\n",
            "[[983   0]\n",
            " [154 139]]\n",
            "AUC Score: 0.995771112322451\n",
            "\n",
            "\n",
            "Model: BernoulliNB\n",
            "Accuracy Score = 0.9780564263322884\n",
            "Confusion Matrix:\n",
            "[[973  10]\n",
            " [ 18 275]]\n",
            "AUC Score: 0.9964516229832059\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Make predictions on random text**"
      ],
      "metadata": {
        "id": "qaXjgzgAWgiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_text = input()\n",
        "\n",
        "preprocessed_text = preprocess_text(random_text)\n",
        "lemmatized_text = lemmatize_text(preprocessed_text)\n",
        "text_vector = vectorizer.transform([lemmatized_text]) #we cannot fit into text_vector. We already trained the vectorizer before. So, through this, we are only going to transform , no need to fit again. The same goes for scaling as well.\n",
        "\n",
        "for model in models:\n",
        "    prediction = model.predict(text_vector)\n",
        "    print(f\"Model: {type(model).__name__}\")\n",
        "    print(\"Prediction:\", prediction)\n",
        "    print('\\n')\n",
        "\n",
        "# 0 -> Good Text, 1-> Spam."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJMEM2yKWeJz",
        "outputId": "d7b75609-07e1-4c9c-ef00-56f49686d3ec"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I need an Iphone.\n",
            "Model: MultinomialNB\n",
            "Prediction: [0]\n",
            "\n",
            "\n",
            "Model: BernoulliNB\n",
            "Prediction: [0]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_text = input()\n",
        "\n",
        "preprocessed_text = preprocess_text(random_text)\n",
        "lemmatized_text = lemmatize_text(preprocessed_text)\n",
        "text_vector = vectorizer.transform([lemmatized_text])\n",
        "\n",
        "for model in models:\n",
        "    prediction = model.predict(text_vector)\n",
        "    print(f\"Model: {type(model).__name__}\")\n",
        "    print(\"Prediction:\", prediction)\n",
        "    print('\\n')\n",
        "\n",
        "# 0 -> Good Text, 1-> Spam."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDssnSNQWj2b",
        "outputId": "8dd5a017-4477-4e8a-8434-c09bd1eba832"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Congratulations! You've won a lottery of $100000. Claim your prize now!\n",
            "Model: MultinomialNB\n",
            "Prediction: [0]\n",
            "\n",
            "\n",
            "Model: BernoulliNB\n",
            "Prediction: [1]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}